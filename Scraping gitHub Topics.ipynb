{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbb820b-c5ca-418f-9b88-4b35c9c1b6dd",
   "metadata": {},
   "source": [
    "# Project Outline\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic , we'll get topic title, topic page URL, and topic description.\n",
    "- For each topic. we'll get the top 25 repositories in the topic from the topic page.\n",
    "- For each repository, we'll grab the repo name, username, stars, and repo URL\n",
    "- For each topic we'll create a CDV file in the following format.\n",
    "```\n",
    "Repo Name,Username,Starts,Repo URL\n",
    "three.js,mrdoob,https://github.com/mrdoob/three.js\n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4a881-3fbf-4b83-824a-9f4a584f23db",
   "metadata": {},
   "source": [
    "# Steps to do:\n",
    "1. Pick a website and describe your objective.\n",
    "2. Use the requests library to download web pages.\n",
    "3. Use Beautiful Soup to parse and extract information.\n",
    "4. Create CSV file(s) with the extracted information.\n",
    "5. Document and share your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7718875-a703-4b3a-81a2-612d60ee5e9e",
   "metadata": {},
   "source": [
    "## 1. Pick a website and describe your objective.\n",
    "- Browse through 'https//:github.com/topics' and scrap the website.\n",
    "- Identify the information you'd like to scrape from the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860c002b-3898-408c-bf46-f7e3f8e221e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/topics'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## github topic url\n",
    "base_url = \"https://github.com/topics\"\n",
    "base_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73986d4-6924-41c2-a173-aeae9ba0bf59",
   "metadata": {},
   "source": [
    "## 2. Use the requests library to download web pages.\n",
    "1. requests\n",
    "2. BeautifulSoup\n",
    "3. os\n",
    "4. pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27ac712-fcda-493f-afde-4662e8ae5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Importing the required libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e5ab1-1d58-46a3-b643-560f4f6d7d75",
   "metadata": {},
   "source": [
    "## 3. Use Beautiful Soup to parse and extract information.\n",
    "- Parse and explore the structure of downloaded web pages using Beautiful soup.\r",
    "- \n",
    "Use the right properties and methods to extract the required informatio.\n",
    "- \r\n",
    "Create functions to extract from the page into lists and dictionaried.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2204d793-fa60-4921-8430-92d452151f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main web page scraping\n",
    "\n",
    "## to read the 'https://github.com/topics in the html parser\n",
    "def read_website_as_html(base_url):\n",
    "    ##reading the website\n",
    "    response = requests.get(base_url)\n",
    "    ## checking the response code whether it successfully read or not\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}'.format(base_url))\n",
    "        return 'Faild to scrap'\n",
    "    ## if we are getinge the 200 as the status_code than it is successfuly read\n",
    "    else:\n",
    "        ## convrting the html pasear in to beautiful html parser\n",
    "        topics_html = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topics_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedfa97d-4fb5-4c31-b68e-25e91408a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getiing the topic names and topic URLs\n",
    "def get_topics_info(topics_html):\n",
    "    ## To get the topic titles\n",
    "    topic_title_tags = topics_html.find_all(\"p\", {'class':\"f3 lh-condensed mb-0 mt-1 Link--primary\"})\n",
    "    topic_titles=list()\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    \n",
    "    ## To get the topic discrptions\n",
    "    topic_disc_tags = topics_html.find_all(\"p\",{\"class\":\"f5 color-fg-muted mb-0 mt-1\"})\n",
    "    topic_disc = list()\n",
    "    for tag in topic_disc_tags:\n",
    "        topic_disc.append(tag.text.strip())\n",
    "\n",
    "    # github url\n",
    "    git_url = 'https://github.com'\n",
    "    topic_urls = topics_html.find_all(\"a\",{'class': \"no-underline flex-1 d-flex flex-column\"})\n",
    "    \n",
    "    \n",
    "    topic_URLs = list()\n",
    "    for tag in topic_urls:\n",
    "        url = \"https://github.com\" + tag['href']\n",
    "        topic_URLs.append(url)\n",
    "        \n",
    "    ## creating the dictnory for topic info\n",
    "    topics_dict = {\n",
    "        'Topic Title' : topic_titles,\n",
    "        'Description': topic_disc,\n",
    "        'Topic_URLs': topic_URLs\n",
    "    }\n",
    "    return topics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32319fb6-c19a-4d59-ad95-edbb63201a6b",
   "metadata": {},
   "source": [
    "## 4. Create CSV file(s) with the extracted information\n",
    "- Create functions for the end-to-end process of downloading, parsing, and saving CSVs.\r",
    "- \n",
    "Execute the function with different inputs to create a dataset of CSV file.s- \r\n",
    "Verify the information in the CSV files by reading them back using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d221f6c-29ce-4691-ac03-1903ed690b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dataframe(topics_dict):\n",
    "    topics_df = pd.DataFrame(topics_dict)\n",
    "    return topics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd3682-efe2-41f2-b346-cfd46c5c6363",
   "metadata": {},
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd1a6c5-c54d-4e05-8fe7-58a1d5d5d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Topic Title                                        Description  \\\n",
      "0                       3D  3D refers to the use of three-dimensional grap...   \n",
      "1                     Ajax  Ajax is a technique for creating interactive w...   \n",
      "2                Algorithm  Algorithms are self-contained sequences that c...   \n",
      "3                      Amp  Amp is a non-blocking concurrency library for ...   \n",
      "4                  Android  Android is an operating system built by Google...   \n",
      "5                  Angular  Angular is an open source web application plat...   \n",
      "6                  Ansible  Ansible is a simple and powerful automation en...   \n",
      "7                      API  An API (Application Programming Interface) is ...   \n",
      "8                  Arduino  Arduino is an open source platform for buildin...   \n",
      "9                  ASP.NET  ASP.NET is a web framework for building modern...   \n",
      "10                    Atom  Atom is a open source text editor built with w...   \n",
      "11           Awesome Lists  An awesome list is a list of awesome things cu...   \n",
      "12     Amazon Web Services  Amazon Web Services provides on-demand cloud c...   \n",
      "13                   Azure  Azure is a cloud computing service created by ...   \n",
      "14                   Babel  Babel is a compiler for writing next generatio...   \n",
      "15                    Bash  Bash is a shell and command language interpret...   \n",
      "16                 Bitcoin  Bitcoin is a cryptocurrency developed by Satos...   \n",
      "17               Bootstrap  Bootstrap is an HTML, CSS, and JavaScript fram...   \n",
      "18                     Bot  A bot is an application that runs automated ta...   \n",
      "19                       C  C is a general purpose programming language th...   \n",
      "20                  Chrome  Chrome is a web browser from the tech company ...   \n",
      "21        Chrome extension  Chrome extensions enable users to customize th...   \n",
      "22  Command line interface  A CLI, or command-line interface, is a console...   \n",
      "23                 Clojure  Clojure is a dynamic, general-purpose programm...   \n",
      "24            Code quality  Automate your code review with style, quality,...   \n",
      "25             Code review  Ensure your code meets quality standards and s...   \n",
      "26                Compiler  Compilers are software that translate higher-l...   \n",
      "27  Continuous integration  Automatically build and test your code as you ...   \n",
      "28                COVID-19  The coronavirus disease 2019 (COVID-19) is an ...   \n",
      "29                     C++  C++ is a general purpose and object-oriented p...   \n",
      "\n",
      "                                          Topic_URLs  \n",
      "0                       https://github.com/topics/3d  \n",
      "1                     https://github.com/topics/ajax  \n",
      "2                https://github.com/topics/algorithm  \n",
      "3                    https://github.com/topics/amphp  \n",
      "4                  https://github.com/topics/android  \n",
      "5                  https://github.com/topics/angular  \n",
      "6                  https://github.com/topics/ansible  \n",
      "7                      https://github.com/topics/api  \n",
      "8                  https://github.com/topics/arduino  \n",
      "9                   https://github.com/topics/aspnet  \n",
      "10                    https://github.com/topics/atom  \n",
      "11                 https://github.com/topics/awesome  \n",
      "12                     https://github.com/topics/aws  \n",
      "13                   https://github.com/topics/azure  \n",
      "14                   https://github.com/topics/babel  \n",
      "15                    https://github.com/topics/bash  \n",
      "16                 https://github.com/topics/bitcoin  \n",
      "17               https://github.com/topics/bootstrap  \n",
      "18                     https://github.com/topics/bot  \n",
      "19                       https://github.com/topics/c  \n",
      "20                  https://github.com/topics/chrome  \n",
      "21        https://github.com/topics/chrome-extension  \n",
      "22                     https://github.com/topics/cli  \n",
      "23                 https://github.com/topics/clojure  \n",
      "24            https://github.com/topics/code-quality  \n",
      "25             https://github.com/topics/code-review  \n",
      "26                https://github.com/topics/compiler  \n",
      "27  https://github.com/topics/continuous-integration  \n",
      "28                https://github.com/topics/covid-19  \n",
      "29                     https://github.com/topics/cpp  \n"
     ]
    }
   ],
   "source": [
    "## Colling the all the functions\n",
    "base_url = 'https://github.com/topics'\n",
    "topics_html = read_website_as_html(base_url)\n",
    "topics_info = get_topics_info(topics_html)\n",
    "df = creating_dataframe(topics_info)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bc378a-a610-4ca4-a152-6faf031a4780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: './Github Topics'\n"
     ]
    }
   ],
   "source": [
    "#path=os.path.join('Github Topics','Topics')\n",
    "path = './Github Topics'\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "    df.to_csv('Github Topics/Topics.csv')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8124c-ca68-47c8-b1ba-11f589c76544",
   "metadata": {},
   "source": [
    "# Scrap each topic inside the GitHub Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5415357b-7a97-4360-aa20-c767fc5b7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## To convert the string value into an integer value\n",
    "## Here 'k' value is replaced with the multiplication with 1000 to the remaining float value\n",
    "def stars_int(star):\n",
    "    star = star.strip()\n",
    "    if star[-1] == 'k':\n",
    "        return int(float(star[:-1]) * 1000)\n",
    "    else:\n",
    "        return int(star)\n",
    "\n",
    "## To get inside each topic of username, repo_name, total no. of stars, and repo_URL\n",
    "def get_repo_info(repo_tag , stars_tag ):\n",
    "    #h\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "    base_url = 'https://github.com'\n",
    "    a_tags = repo_tag.find_all('a')\n",
    "    user_name = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    stars = stars_int(stars_tag)\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    return user_name, repo_name,stars, repo_url\n",
    "\n",
    "\n",
    "## scrap the repo_tags and stars\n",
    "## To Scrap the each topic information with the topic url\n",
    "def get_topic_repos(topic_url):\n",
    "    ## check the topic status code\n",
    "    response =requests.get(topic_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "        \n",
    "    doc = BeautifulSoup(response.text,'html.parser')\n",
    "   \n",
    "    repo_tags = doc.find_all('h3', {'class':\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "    stars = doc.find_all('span',{'class':\"Counter js-social-count\"})\n",
    "\n",
    "\n",
    "    topic_repos_dict = {\n",
    "        'username': [],\n",
    "        'repo_name': [],\n",
    "        'stars': [],\n",
    "        'repo_url': []\n",
    "    }\n",
    "    ## Adding all values to the dictionary.\n",
    "    \n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i],stars[i].text)\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "\n",
    "    ## Creating the pandas' data frame with the dictionary.\n",
    "    df = pd.DataFrame(topic_repos_dict)\n",
    "\n",
    "    return df\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7fc15f-812c-4599-b881-b01a5e733fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/topics/3d\n",
      "https://github.com/topics/ajax\n",
      "https://github.com/topics/algorithm\n",
      "https://github.com/topics/amphp\n",
      "https://github.com/topics/android\n",
      "https://github.com/topics/angular\n",
      "https://github.com/topics/ansible\n",
      "https://github.com/topics/api\n",
      "https://github.com/topics/arduino\n",
      "https://github.com/topics/aspnet\n",
      "https://github.com/topics/atom\n",
      "https://github.com/topics/awesome\n",
      "https://github.com/topics/aws\n",
      "https://github.com/topics/azure\n",
      "https://github.com/topics/babel\n",
      "https://github.com/topics/bash\n",
      "https://github.com/topics/bitcoin\n",
      "https://github.com/topics/bootstrap\n",
      "https://github.com/topics/bot\n",
      "https://github.com/topics/c\n",
      "https://github.com/topics/chrome\n",
      "https://github.com/topics/chrome-extension\n",
      "https://github.com/topics/cli\n",
      "https://github.com/topics/clojure\n",
      "https://github.com/topics/code-quality\n",
      "https://github.com/topics/code-review\n",
      "https://github.com/topics/compiler\n",
      "https://github.com/topics/continuous-integration\n",
      "https://github.com/topics/covid-19\n",
      "https://github.com/topics/cpp\n"
     ]
    }
   ],
   "source": [
    "## Each topic urls\n",
    "df= pd.read_csv('Github Topics/Topics.csv')['Topic_URLs']\n",
    "for i in range(len(df)):\n",
    "    print(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8706aa3d-1991-452a-9f3a-a6198af8f662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: './Github Topics/Topics'\n",
      "Scraping is successfully completed 3D.\n",
      "Scraping is successfully completed Ajax.\n",
      "Scraping is successfully completed Algorithm.\n",
      "Scraping is successfully completed Amp.\n",
      "Scraping is successfully completed Android.\n",
      "Scraping is successfully completed Angular.\n",
      "Scraping is successfully completed Ansible.\n",
      "Scraping is successfully completed API.\n",
      "Scraping is successfully completed Arduino.\n",
      "Scraping is successfully completed ASP.NET.\n",
      "Scraping is successfully completed Atom.\n",
      "Scraping is successfully completed Awesome Lists.\n",
      "Scraping is successfully completed Amazon Web Services.\n",
      "Scraping is successfully completed Azure.\n",
      "Scraping is successfully completed Babel.\n",
      "Scraping is successfully completed Bash.\n",
      "Scraping is successfully completed Bitcoin.\n",
      "Scraping is successfully completed Bootstrap.\n",
      "Scraping is successfully completed Bot.\n",
      "Scraping is successfully completed C.\n",
      "Scraping is successfully completed Chrome.\n",
      "Scraping is successfully completed Chrome extension.\n",
      "Scraping is successfully completed Command line interface.\n",
      "Scraping is successfully completed Clojure.\n",
      "Scraping is successfully completed Code quality.\n",
      "Scraping is successfully completed Code review.\n",
      "Scraping is successfully completed Compiler.\n",
      "Scraping is successfully completed Continuous integration.\n",
      "Scraping is successfully completed COVID-19.\n",
      "Scraping is successfully completed C++.\n",
      "Scraping was done...\n"
     ]
    }
   ],
   "source": [
    "path = './Github Topics/Topics'\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "topic_url= pd.read_csv('Github Topics/Topics.csv')['Topic_URLs']\n",
    "topic_title = pd.read_csv('Github Topics/Topics.csv')['Topic Title']\n",
    "for i in range(len(topic_url)):\n",
    "    df = get_topic_repos(topic_url[i])\n",
    "    df.to_csv(path+'_'+str(topic_title[i])+'.csv')\n",
    "    print(f'Scraping is successfully completed {topic_title[i]}.')\n",
    "print('Scraping was done...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2837d-8c76-4ba8-9aef-d10a1e733c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
